<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 1</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <h1>Chapter Two Answers</h1>

<h2>Question 4</h2>
<details>
    Fred is answering a multiple-choice problem on an exam, and has to choose one of n
options (exactly one of which is correct). Let K be the event that he knows the answer,
and R be the event that he gets the problem right (either through knowledge or through
luck). Suppose that if he knows the right answer he will definitely get the problem right,
but if he does not know then he will guess completely randomly. Let P(K) = p.<br><br>
(a) Find P(K|R) (in terms of p and n).<br>
(b) Show that P(K|R) ≥ p, and explain why this makes sense intuitively. When (if ever)
does P(K|R) equal p?
  <summary>Question</summary>
</details>
<details>
  A)
  $$
  P(K|R) = \dfrac{p}{p + (1-p)/n}
  $$
    B) Intuitivly, 
    \(P(K|R)\) will always be greater than or equal to \(p\) because getting the answer right is usually evidence in favor of knowlege.<br>
    When \(p=1\) or \(p=0\), then \(P(K|R)=p\)
  <summary>Answer</summary>
</details>

<details>
    This equation might not look like Bayes because \(P(R|K) = 1\), and therefore we can implicitly multiply by 1.
  <summary>Explanation</summary>
</details>

<h2>Question 6</h2>
<details>
    
    <summary>Question</summary>
</details>
<details>
    $$
    P(D|H) = \dfrac{.01}{(.01)+(.99 \cdot .5^7)} \approx 0.564
    $$
    <summary>Answer</summary>
</details>
<details>
    First let's define our events
    \(
    D = \text{double-sided coin selected}
    \)
    \(
    H = seven heads in a row
    \)
    We are told that \(P(D) = .01\) and \(P(H|D) = 1\).  With a bit of common sense we can finish building this equation
    $$
    P(D|H) = \dfrac{P(H) \cdot P(H|D)}{P(D) \cdot P(H|D) + P(D^c) \cdot .5^7}
    $$
    \(.5^7\) is the probability of flipping a fair coin 7 times and getting heads heach time.
    
    <summary>Explanation</summary>
</details>

<h2>Question 7</h2>
<details>
    
    <summary>Question</summary>
</details>
<details>
    A)
    $$
	P(D|H) = \dfrac{\dfrac{1}{2} \left(\dfrac{99}{100} \cdot \left(\dfrac{1}{2}\right)^7 + \dfrac{1}{100}\right)}
	{\dfrac{1}{2} \left(\dfrac{99}{100} \cdot \left(\dfrac{1}{2}\right)^7 + \dfrac{1}{100}\right) + \left(\dfrac{1}{2}\right)^8 } \approx .694
    $$
    B)
    $$
    P(D|H) = \dfrac{.005}{.005 + (.995 \cdot .5^7)} \approx .391
    $$
    <summary>Answer</summary>
</details>
<details>
    <summary>Explanation</summary>
</details>

<h2>Question 8</h2>
<details>
	The screens used for a certain type of cell phone are manufactured by 3 companies,
A, B, and C. The proportions of screens supplied by A, B, and C are 0.5, 0.3, and
0.2, respectively, and their screens are defective with probabilities 0.01, 0.02, and 0.03,
respectively. Given that the screen on such a phone is defective, what is the probability
that Company A manufactured it?
	<summary>Question</summary>
</details>
<details>
	$$
	P(A|D) = \dfrac{\frac{1}{200} }{\frac{1}{200} + 2(\frac{3}{500}) } = \dfrac{5}{17}
	$$
	<summary>Answer</summary>
</details>
<details>
	The numerator is the probability that a screen made by company A is defective times the probability that a screen is made by company A, which is \(.5 \cdot .01\) or \(\dfrac{1}{200}\)<br>
	The denominator is the probability that any screen is defective.  We find this by adding up the probability of each company making a screen and probability that a screen by that company is defective.
	<summary>Explanation</summary>
</details>

<h2>Chapter 9</h2>
<details>
	(a) Show that if events A1 and A2 have the same prior probability P (A1) = P (A2),
A1 implies B, and A2 implies B, then A1 and A2 have the same posterior probability
P (A1|B) = P (A2|B) if it is observed that B occurred.<br>
(b) Explain why (a) makes sense intuitively, and give a concrete example.
	<summary>Question</summary>
</details>
<details>
	A)<br>
	If two events have the same prior probability, that means they are equally likely to happen.  If they both imply the same event and that event happens, that just means the probability of each event stays the same.<br>
	B) <br>
	If there is a 10 percent chance of rain and a 10 percent chance of thunder, and both events imply clouds, then the fact that it is cloudy changes nothing.
	<summary>Answer</summary>
</details>

<h2>Question 10</h2>
<details>
	Fred is working on a major project. In planning the project, two milestones are set up,
with dates by which they should be accomplished. This serves as a way to track Fred’s
progress. Let A1 be the event that Fred completes the first milestone on time, A2 be
the event that he completes the second milestone on time, and A3 be the event that he
completes the project on time.
Suppose that \(P(A_{j+1}|A_j )=0.8\) but \(P(Aj+1|A^c_j )=0.3\) for j = 1, 2, 3. If Fred falls
behind on his schedule it will be hard for him to get caught up. Also, assume that the
second milestone supersedes the first, in the sense that once we know whether he is
on time in completing the second milestone, it no longer matters what happened with
the first milestone. We can express this by saying that \(A_1\) and \(A_3\) are conditionally
independent given \(A_2\) and they’re also conditionally independent given \(A^c_2\).
<br><br>
(a) Find the probability that Fred will finish the project on time, given that he completes
the first milestone on time. Also find the probability that Fred will finish the project on
time, given that he is late for the first milestone.<br>
(b) Suppose that P(A1)=0.75. Find the probability that Fred will finish the project
on time.
	<summary>Question</summary>
</details>
<details>
	A)
	$$
	P(A_3|A_1) = .8^2 + .2(.3) = .7
	$$
	$$
	P(A_3|A_1^c) = .3(.8) + .7(.3) = .45
	$$
	B)
	$$
	P(A_3) = 0.75 \cdot 0.8 \cdot 0.8 + 0.75 \cdot 0.2 \cdot 0.3 + 0.25 \cdot 0.3 \cdot 0.8 + 0.25 \cdot 0.7 \cdot 0.3 = .6375
	$$
	<summary>Answer</summary>
</details>
<details>
	A)<br>
	Let's break this down at into smaller parts.  First we look at the probabilies for event \(A_2\)
	$$
	P(A_2|A_1) = .8
	$$
	$$
	P(A_2^c|A_1) = .2
	$$
	$$
	P(A_3|P_2) = .8P(A_2|A_1)
	$$
	$$
	P(A_3|P_2^c) = .3P(A_2^c|A_1)
	$$
	$$
	P(A_3|P_1) = P(A_3|P_2^c) + P(A_3|P_2)
	$$
	When we plug in the values for the right-hand side of that equation, we get the answer.  Notice that we only end up with two cases being added, this is because \(A_2\) and \(A_2^c\) are mutually exclusive.<br>
	<br>
	We do the same thing for \(P(A_3|A_1^c)\) except the values are
	$$
	P(A_2|A_1^c) = .3
	$$
	$$
	P(A_2^c|A_1^c) = .7
	$$
	$$
	P(A_3|A_2) = .8P(A_2|A_1^c)
	$$
	$$
	P(A_3|A_2^c) = .3P(A_2^c|A_1^c)
	$$
	Now we have everything we need to solve for \(P(A_3|A_1^c)\)<br><br>
	B)<br>
	Now we will have four cases to add together, they are
	$$
	P(A_3|A_2,A_1) = .75(.8 \times .8)
	$$
	$$
	P(A_3|A_2,A_1^c) = .25(.3 \times .8)
	$$
	$$
	P(A_3|A_2^c|A_1) = .75(.2 \times .3)
	$$
	$$
	P(A_3|A_2^c|A_1^c) = .25(.7 \times .3)
	$$
	The sum of these will gie us the answer for \(P(A_3)\).
	<summary>Explanation</summary>
</details>

<h2>Question 11</h2>
<details>
	An exit poll in an election is a survey taken of voters just after they have voted. One
major use of exit polls has been so that news organizations can try to figure out as soon as possible who won the election, before the votes are officially counted. This has
been notoriously inaccurate in various elections, sometimes because of selection bias:
the sample of people who are invited to and agree to participate in the survey may not
be similar enough to the overall population of voters.
Consider an election with two candidates, Candidate A and Candidate B. Every voter
is invited to participate in an exit poll, where they are asked whom they voted for; some
accept and some refuse. For a randomly selected voter, let A be the event that they voted
for A, and W be the event that they are willing to participate in the exit poll. Suppose
that P(W|A)=0.7 but P(W|A
c
)=0.3. In the exit poll, 60% of the respondents say
they voted for A (assume that they are all honest), suggesting a comfortable victory for
A. Find P(A), the true proportion of people who voted for A.
	<summary>Question</summary>
</details>
<details>
	$$
	P(A) \approx .391
	$$
	<summary>Answer</summary>
</details>
<details>
	To find \(P(A)\), we find the equation for \(P(A|W)\) and then solve for \(P(A)\).
	$$
	P(A|W) = \dfrac{.7x}{.7x + .3(1-x)} = .6
	$$
	Noticed I replaced \(P(A)\) with \(x\) for clarity.<br>
	Now solve for \(x\) to get the answer.
	<summary>Explanation</summary>
</details>

<h2>Question 12</h2>
<details>
	Alice is trying to communicate with Bob, by sending a message (encoded in binary)
across a channel.<br><br>
(a) Suppose for this part that she sends only one bit (a 0 or 1), with equal probabilities.
If she sends a 0, there is a 5% chance of an error occurring, resulting in Bob receiving a
1; if she sends a 1, there is a 10% chance of an error occurring, resulting in Bob receiving
a 0. Given that Bob receives a 1, what is the probability that Alice actually sent a 1?<br>
(b) To reduce the chance of miscommunication, Alice and Bob decide to use a repetition
code. Again Alice wants to convey a 0 or a 1, but this time she repeats it two more times,
so that she sends 000 to convey 0 and 111 to convey 1. Bob will decode the message by
going with what the majority of the bits were. Assume that the error probabilities are
as in (a), with error events for different bits independent of each other. Given that Bob
receives 110, what is the probability that Alice intended to convey a 1?
	<summary>Question</summary>
</details>
<details>
	A)
	$$
	P(S_1|R_1) = \dfrac{.5 \cdot .9}{(\frac{.9}{2})+(\frac{.05}{2})} \approx .947
	$$
	B)
	$$
	P(S_1|R_{110}) = \dfrac{\frac{.081}{2}}{\frac{.081}{2}+\frac{.0023}{2}} \approx .972
	$$
	<summary>Answer</summary>
</details>
<details>

	<summary>Explanation</summary>
</details>

<h2>Question 13</h2>
<details>
	Company A has just developed a diagnostic test for a certain disease. The disease
afflicts 1% of the population. As defined in Example 2.3.9, the sensitivity of the test is
the probability of someone testing positive, given that they have the disease, and the
specificity of the test is the probability that of someone testing negative, given that they
don’t have the disease. Assume that, as in Example 2.3.9, the sensitivity and specificity
are both 0.95.
Company B, which is a rival of Company A, offers a competing test for the disease.
Company B claims that their test is faster and less expensive to perform than Company
A’s test, is less painful (Company A’s test requires an incision), and yet has a higher
overall success rate, where overall success rate is defined as the probability that a random
person gets diagnosed correctly.<br><br>
(a) It turns out that Company B’s test can be described and performed very simply: no
matter who the patient is, diagnose that they do not have the disease. Check whether
Company B’s claim about overall success rates is true.<br>
(b) Explain why Company A’s test may still be useful.<br>
(c) Company A wants to develop a new test such that the overall success rate is higher
than that of Company B’s test. If the sensitivity and specificity are equal, how high
does the sensitivity have to be to achieve their goal? If (amazingly) they can get the
sensitivity equal to 1, how high does the specificity have to be to achieve their goal? If
(amazingly) they can get the specificity equal to 1, how high does the sensitivity have
to be to achieve their goal?
	<summary>Question</summary>
</details>
<details>
	A)
	first we define our events
	$$
	D = \text{has disease}
	$$
	$$
	T_p = \text{tests positive}
	$$
	$$
	T_n = \text{tests negative}
	$$
	With those events defined, we can set up an equation to see how likely a person is to actually have a disease given that company A's test gave them a positive result.
	$$
	P(D|T_p) = \dfrac{.01 \times .95}{(.01 \times .95) + (.99 \times .05)} \approx .161
	$$
	And an equation for how likely someone is to not be diseased given a negative result.
	$$
	P(D^c|T_n) = \dfrac{.99 \times .95}{(.99 \times .95) + (.01 \times .05)} \approx .998
	$$
	This means that using company A's test, there is a \(1-.161\) false positive and basically no false negative.<br>
	Company B has a false negative of .01 and a false positive of 0, so in the general population, company B performs much better.<br><br>
	B) <br>
	This may lead some to believe that company A's test is useless or even fake!  This is misguided though.  Company A's test could still be usefull if there is a population where the rate of disease is higher than the general population.<br>
	You may crunch the numbers and find out what the precision of both tests are when the prior probability of having the disease is \(.5\).  Also, If company A gives multiple tests to each patient and uses the majority to decide, accuracy will be improved.<br>
	<br> lastly, company A's test can allow us to update our probability that a patient has the disease, while company B's test does not do this at all.  Notice that the accuracy of a test is not the only important thing about a test!<br><br>
	C)<br>
	If sensitivity and specificity must be the same, then company A's test will outperform company B's test when both are greater than .99<br>
	iF sensitivity is 1, then specificity must be really close to .99 or better<br>
	when specificity is 1, then sensitivity must be better than 0.<br>
	Because most people do not have the disease, it is more important not to get false positives than to avoid false negatives.  
	<summary>Answer</summary>

</details>

<h2>Question 14</h2>
<details>
	Consider the following scenario, from Tversky and Kahneman:<br><br>
	<em>Let A be the event that before the end of next year, Peter will have installed
a burglar alarm system in his home. Let B denote the event that Peter’s
home will be burglarized before the end of next year.
		</em>
(a) Intuitively, which do you think is bigger, P (A|B) or P (A|Bc)? Explain your intuition.<br>
(b) Intuitively, which do you think is bigger, P (B|A) or P (B|Ac)? Explain your intuition.<br>
(c) Show that for any events A and B (with probabilities not equal to 0 or 1), P (A|B) >
P (A|Bc) is equivalent to P (B|A) > P (B|Ac).<br>
(d) Tversky and Kahneman report that 131 out of 162 people whom they posed (a)
and (b) to said that P (A|B) > P (A|Bc) and P (B|A) < P (B|Ac). What is a plausible
explanation for why this was such a popular opinion despite (c) showing that it is
impossible for these inequalities both to hold?<br>
	<summary>Question</summary>
</details>
<details>
	A)<br>
	Intuitively, I would think that \(P(A|B)\) is higher than \(P(A|B^c)\) because if his house gets broaken into, he is more likely to install the burgaler alarm.<br>
	B)<br>
	Here my intuition says \(P(B|A^c)\) should be greater than \(P(B|A)\), but this cannot be the case if the above condition holds.<br>
	C)<br>
	We use the definition of dependent probability to demostrate why \(P(A|B) \gt P(A|B^c)\) is equivelant to \(P(B|A) \tg P(B|A^c)\) as long as both \(P(A)\) and \(P(B)\) are not 0 or 1.<br>
	$$
	\dfrac{P(B\cap A}{P(A)} \gt \dfrac{P(B\cap A^c)}{A^c}
	$$
	and
	$$
	\dfrac{P(A\cap B)}{P(B)} \gt \dfrac{P(A \cap B^c}{P(B^c)}
	$$
	plug in any number otherthan 0 or 1 for both probabilities and see if they hold, this should give you a better intuition about why this is true
	<summary>Answer</summary>
</details>

<h2>Question 15</h2>
<details>
	<summary>Question</summary>
</details>
<details>
	$$
	A
	$$
	
	<summary>Answer</summary>
</details>
<details>
	of the options, A is the least likely to have occured, therefor it is best to see that event occure if we want both A and B to occure.<br>
	seeing the event \(A\cup B\) does not give us as much information because it is the most probable.
	<summary>Explanation</summary>
</details>

<h2>Question 16</h2>
<details>
	Show that P (A|B) \(\le\) P (A) implies P(A|B^c) \(\ge\) P(A), and give an intuitive explanation
of why this makes sense.
	<summary>Question</summary>
</details>
<details>
	Intuitively, we can view the events as circles in a ven diagram. When we say \(P(A|B) \le P(A)\), we are saying that at most half of \(P(A|B)\) is inside of \(P(A)\).<br>
	This means that half or more of \(P(A|B)\) lies outside \(P(A)\).
	<summary>Answer</summary>
</details>

<h2>Question 17</h2>
<details>
In deterministic logic, the statement “A implies B” is equivalent to its contrapositive,
“not B implies not A”. In this problem we will consider analogous statements in prob-
ability, the logic of uncertainty. Let A and B be events with probabilities not equal to
0 or 1.<br><br>
(a) Show that if P \((B|A) = 1\), then P \((A^c|B^c) = 1\).<br>
Hint: Apply Bayes’ rule and LOTP.
(b) Show however that the result in (a) does not hold in general if = is replaced by \(\approx\).
In particular, find an example where \(P (B|A)\) is very close to 1 but \(P (A^c|B^c)\) is very
close to 0.
	<summary>Question</summary>
</details>
<details>
	A) If B is guarenteed to occure then A occures, that means A is a subset of B.  Therefore if B does not occure, then A also cannot occure.<br>
	We can denonstrate this using Bayes theorem.
	$$
	P(B|A) = \dfrac{P(B) \cdot P(A|B)}{ P(B) P(A|B) + P(B^c) P(A|B^c) } = 1
	$$
	For the denomniator, we know that \(P(B^c) P(A|B^c)\) must be zero for this equation to equal 1 according to LOTP.<br>
	Therefore, \(P(A^c|B^c)\) must equal 1.<br>
	B)
	if \(P(B|A) = .99\), then A is not a subset of B, therefore it is no longer a guarentee that \(P(A^c|B^c) \approx 1\).<br>
	If your sample space is not much larger than \(A \cup B\), then you can have a situation where \(P(B|A) \approx 1\) but \(P(A^c|B^c) \approx 0\)<br>
	For example, let A be the probability that someone has a very common disease and let B be the probability that someone tests positive for the disease.<br>
	Assuming that almost everyone with the disease tests positive, with only a few false negatives.  Let B = test positive and A = has disease.  If only a few people have the disease and test negative but even fewer people test positve, then \(P(A^c|B^c) \approx 0\)<br>
	<br>
	A simpler answer I arrived at via the hint is that A and B can occure with probability close to 1 as independent events.
	
	
	<summary>Answer</summary>
</details>

<h2>Question 18</h2>
<detials>
	
	<summary>Question</summary>
</detials>
<details>
	When \(P(A) = 1\), then bayes theorem looks like this:
	$$
	P(A|B) = \dfrac{P(B|A)  }{P(B|A)} = 1
	$$
	Intuitively, If you believe something is guarenteed to happen, no data can change that.  If you are sure you have cancer, then a test result saying you do not have cancer will be totally unconvincing.<br>
	<summary>Answer</summary>
</details>
	
<h2>Question 20</h2>
<details>
	The Jack of Spades (with cider), Jack of Hearts (with tarts), Queen of Spades (with a
wink), and Queen of Hearts (without tarts) are taken from a deck of cards. These four
cards are shuffled, and then two are dealt.<br><br>
(a) Find the probability that both of these two cards are queens, given that the first
card dealt is a queen.<br>
(b) Find the probability that both are queens, given that at least one is a queen.<br>
(c) Find the probability that both are queens, given that one is the Queen of Hearts.<br>
	<summary>Question</summary>
</details>
<details>
	A)
	$$
	P(\text{both}| \text{first}) = \dfrac{ 1 }{ {3 \choose 1} } = \dfrac{1}{3}
	$$
	B)
	$$
	P(\test{both}| \test{either}) = \dfrac{1}{ {5 \choose 1} -1 } = \dfrac{1}{5}
	$$
	C)
	$$
	P(\text{both}|\text{queen of hearts}) = \dfrac{1}{3}
	$$
	
	<summary>Answer</summary>
</details>
<details>
	These are easiest to understand if we simply write out all possible events meeting the first condition then count the events where the first two cards are queens.<br><br>
	A) there are 3 events where a queen is first and 1 where the first two cards are both queens<br>
	$$
	QQJJ \cdot
	$$
	$$
	QJQJ
	$$
	$$
	QJJQ
	$$
	B) There are 5 events where at least 1 of the first two is a queen and 1 where both are queens<br>
	$$
	QQJJ \cdot
	$$
	$$
	QJQJ
	$$
	$$
	QJJQ
	$$
	$$
	JQQJ
	$$
	$$
	JQJQ
	$$
	C) For this one, we must use labeled cards, so I will use \(q\) and \(Q\).  There are 2 where both are queens and 6 in total.  Uppercase \(Q\) will represent queen of hearts<br>
	$$
	qQJJ \cdot
	$$
	$$
	QqJJ \cdot
	$$
	$$
	QJqJ
	$$
	$$
	QJJq
	$$
	$$
	JQqJ
	$$
	$$
	JQJq
	$$
	<summary>Explanation</summary>
</details>

<h2>Question 21</h2>
<details>
	A fair coin is flipped 3 times. The toss results are recorded on separate slips of paper
(writing “H” if Heads and “T” if Tails), and the 3 slips of paper are thrown into a hat.<br><br>
(a) Find the probability that all 3 tosses landed Heads, given that at least 2 were Heads.<br>
(b) Two of the slips of paper are randomly drawn from the hat, and both show the
letter H. Given this information, what is the probability that all 3 tosses landed Heads?
	<summary>Question</summary>
</details>
<details>
	A)
	$$
	P(3 heads | 2 heads) = \dfrac{1}{4}
	$$
	B)
	$$
	P(3 heads | 2 random) = \dfrac{1}{2}
	$$
	<summary>Answer</summary>
</details>
<details>
	What!  How could these possibly be different?  It seems like having at least two heads is the same as pulling 2 random H's out of a hat, but these are indeed different.<br><br>
	A) In the case of 2 or more heads, we add up all the ways we can have either 2 or 3 heads.  There are 3 ways to have 2 heads and 1 way to have 3.<br>
	B) When randomly pullying 2 H's, there are 3 ways to do that when there are 3 heads and 3 ways when there are 2 heads.
	
	<summary>Explanation</summary>
</details>

<h2>Question 22</h2>
<details>
	A bag contains one marble which is either green or blue, with equal probabilities. A
green marble is put in the bag (so there are 2 marbles now), and then a random marble
is taken out. The marble taken out is green. What is the probability that the remaining
marble is also green?
	<summary>Question</summary>
</details>
<details>
	$$
	P(GreenRemains | GreenRemoved) = \dfrac{2}{3}
	$$
	<summary>Answer</summary>
</details>
<details>
	There are 2 equally likely combinations of marbles after the green one is added, those are GG and GB.  If a green marble is taken out, then we are left with B,G, and G again.  Each being equally likely.
	<summary>Explanation</summary>
</details>

<h2>Question 23</h2>
<details>
	Let G be the event that a certain individual is guilty of a certain robbery. In gathering
evidence, it is learned that an event \(E_1\) occurred, and a little later it is also learned that
another event \(E_2\) also occurred. Is it possible that individually, these pieces of evidence
increase the chance of guilt (so \(P (G|E_1) > P (G)\) and \(P (G|E_2) > P\) (G)), but together
they decrease the chance of guilt (so \(P (G|E_1, E_2) < P\) (G))?
	<summary>Question</summary>
</details>
<details>
	This is possible.<br>
	Maybe we know that The suspect was at the location 5 hours before it was robbed, and the suspect also was there 2 hour after it was robbed.  Either one of these make him more likely to rob the store, but together it just means he had a 7 hour shift.    
	<summary>Answer</summary>
</details>

<h2>Question 24</h2>
<details>
	Is it possible to have events A1, A2, B, C with P (A1|B) > P (A1|C) and P (A2|B) >
P (A2|C), yet P (A1 \(\cup\) A2|B) \(\lt\) P (A1 \(\cup\) A2|C)? If so, find an example (with a “story”
interpreting the events, as well as giving specific numbers); otherwise, show that it is
impossible for this phenomenon to happen
	<summary>Question</summary>
</details>
